---
editor: 
  markdown: 
    wrap: 72
---

# Bitácora 3

## Parte de Planificación

### Ajuste de la frecuencia

```{r echo=FALSE, message=FALSE, warning=TRUE}
#| output: false
#| warning: false

library(readxl)
library(kableExtra)
library(readr)
library(dplyr)
library(janitor) # función clean_names()
library(magrittr) # función %<>%
library(stringr) # función str_replace
library(lubridate)
library(PerformanceAnalytics) # funciones skewness y kurtosis
library(ggplot2)
library(actuar)
library(fitdistrplus)
library(stats)
library(cowplot) # mejorar el aspecto de los gráficos
library(gamlss) #distribucion Johnson SU
library(glogis) #distribucion logistica generalizada
```

```{r, warning=FALSE, message=FALSE}
#| echo: false
#| warning: false

datos <- read_excel("claims-2010-2013.xlsx") %>%

clean_names() # se limpian nombres columnas

datos <- datos %>% mutate(date_received = ymd(date_received),

close_amount = as.numeric(gsub("\\$", "", close_amount)))

# Se fija la base de datos

attach(datos)
```

```{r, message=FALSE, warning=FALSE}
#| echo: false

# X: Severidad

# N: Frecuencia

# Se filtran los reclamos aprobados o en los que se llegó a un acuerdo

datos_agregados <- datos %>% 
  filter(disposition == "Settle" | disposition== "Approve in Full")

datos_agregados <- datos_agregados %>% 
  group_by("ano" = year(date_received), "mes" = month(date_received) ) %>% 
  summarise(X = sum(close_amount), N = n()) %>%
  ungroup() %>% mutate(t = c(1:48), .before = X)

```


```{r Distribución empírica frecuencia, echo=FALSE}
F_N <- ecdf(datos_agregados$N)
```

En la @fig-ajustePoisson se muestra el ajuste de la distribución
Poisson, y su versión truncada y modificada en cero, donde se comprueba
que estas no difieren mucho entre sí, aparte de que se observa que el
ajuste no es bueno.

```{r Ajuste Poisson, echo=FALSE, warning=FALSE}
#| fig-cap: "Ajustes distribución Poisson"
#| label: fig-ajustePoisson
#| echo: false
fit_Poisson <- fitdist(data = datos_agregados$N,distr = "pois", method = "mle")

fit_ZTPoisson <- fitdist(data = datos_agregados$N,distr = "ztpois", method = "mle", start = list(lambda=10))

fit_ZMPoisson <- fitdist(data = datos_agregados$N,distr = "zmpois", method = "mle", start = list(lambda=10, p0=0.1), lower=c(0,0), upper=c(Inf, 1))

cdfcomp(cex=0.8, list(fit_Poisson, fit_ZTPoisson, fit_ZMPoisson),main="", xlab="Datos de frecuencia", ylab = "Función de distribución", legend=c("Poisson","Truncada","Modificada"))

# gofstat(list(fit_Poisson, fit_ZTPoisson, fit_ZMPoisson))

```

En la @fig-ajustebinneg se muestra el ajuste de la distribución binomial
negativa, y su versión truncada y modificada en cero, donde se comprueba
que estas no difieren mucho entre sí, aparte de que se observa que el
ajuste es un poco mejor que el de la Poisson, sin llegar a ser
satisfactorio.

```{r Ajuste Binomial negativa, echo=FALSE, warning=FALSE}
#| fig-cap: "Ajustes distribución binomial negativa"
#| label: fig-ajustebinneg
#| echo: false
#| 
fit_Nbinom <- fitdist(data = datos_agregados$N, distr = "nbinom", method = "mle")

fit_ZTNbinom <- fitdist(data = datos_agregados$N, distr = "ztnbinom", method = "mle", start = list(size=1, prob=0.3),  lower=c(0,0), upper=c(Inf, 1))

fit_ZMNbinom <- fitdist(data = datos_agregados$N, distr = "zmnbinom", method = "mle", start = list(size=1, prob=0.3, p0=0.3),  lower=c(0, 0, 0), upper=c(Inf, 1, 1))

cdfcomp(cex=0.8, list(fit_Nbinom, fit_ZTNbinom, fit_ZMNbinom),main="", xlab="Datos de frecuencia", ylab = "Función de distribución", legend=c("Binomial\n negativa","Truncada","Modificada"))
# gofstat(list(fit_Nbinom, fit_ZTNbinom, fit_ZMNbinom))
```

En la @fig-ajustegeom se muestra el ajuste de la distribución
geométrica, y su versión truncada y modificada en cero, donde se
comprueba que estas no se diferencian mucho. Siendo esta distribución un
caso particular de la binomial negativa, se ve que el ajuste es muy
inferior al del caso general. No es claro si el ajuste de la geométrica
es mejor al de la Poisson.

```{r Ajuste Geométrica, echo=FALSE, warning=FALSE}
#| fig-cap: "Ajustes distribución geométrica"
#| label: fig-ajustegeom
#| echo: false
#| 
fit_Geom <- fitdist(data = datos_agregados$N, distr = "geom", method = "mle")

fit_ZTGeom <- fitdist(data = datos_agregados$N, distr = "ztgeom", method = "mle",  start = list(prob = 0.8))

fit_ZMGeom <- fitdist(data = datos_agregados$N, distr = "zmgeom", method = "mle",  start = list(prob = 0.8, p0=0.3), lower=c( 0, 0), upper=c(1, 1))


cdfcomp(cex=0.8, list(fit_Geom, fit_ZTGeom, fit_ZMGeom),main="", xlab="Datos de frecuencia", ylab = "Función de distribución", legend=c("Geométrica","Truncada","Modificada"))
# gofstat(list(fit_Geom, fit_ZTGeom, fit_ZMGeom))
```

A continuación, en la @fig-ajustebinom, se presenta el ajuste de la
distribución binomial, el cual luce similar al de la Poisson y se ve que
no es muy bueno.

```{r Ajuste Binomial, echo=FALSE, warning=FALSE, message=FALSE}
#| fig-cap: "Ajustes distribución binomial"
#| label: fig-ajustebinom
#| echo: false
#| 
m <- max(datos_agregados$N)
fit_Binom <- fitdist(data = datos_agregados$N, dist = "binom", method = "mle", start = list(prob = 0.5, size = m+500), lower=c(0,m-1), upper=c(1, Inf))

fit_ZTBinom <- fitdist(data = datos_agregados$N, dist = "ztbinom", method = "mle", start = list(prob = 0.5, size = m+500), lower=c(0,m-1), upper=c(1, Inf))

fit_ZMBinom <- fitdist(data = datos_agregados$N, dist = "zmbinom", method = "mle", start = list(prob = 0.5, size = m+500, p0=0.01), lower=c(0, m-1, 0), upper=c(1, Inf, 1))

fit_Binom$estimate[2] <- round(fit_Binom$estimate[2])
fit_ZMBinom$estimate[2] <- round(fit_ZMBinom$estimate[2])
fit_ZTBinom$estimate[2] <- round(fit_ZTBinom$estimate[2])


cdfcomp(cex=0.8, list(fit_Binom, fit_ZTBinom, fit_ZMBinom), main="", xlab="Datos de frecuencia", ylab = "Función de distribución", legend=c("Binomial","Truncada","Modificada"))
        
# gofstat(list(fit_Binom, fit_ZTBinom, fit_ZMBinom))


# m <- max(datos_agregados$N)
# binomial_loglik <- data.frame(
#   size = numeric(0),
#   prob = numeric(0),
#   loglik = numeric(0)
# )
# for (s in (99000):(100000)) {
#   fit_Binom <- fitdist(
#     data = datos_agregados$N,
#     dist = "binom",
#     fix.arg = list(size = s),
#     start = list(prob = 0.01)
#   )
#   binomial_loglik <- rbind(
#     binomial_loglik,
#     data.frame(
#       size = s,
#       prob =   fit_Binom$estimate,
#       fit = dbinom(
#         x = s,
#         size = s,
#         prob = fit_Binom$estimate["prob"]
#       ),
#       loglik = fit_Binom$loglik
#     )
#   )
# }
# 
# pos_max <- which.max(binomial_loglik$loglik)
# 
# binomial_loglik[pos_max,]
# 

# # Se hace la optimización de forma manual
# logvero <- function(x, m){
#   q = mean(x)/m
#   l <- -sum(dbinom(x, size = m, prob=q, log = TRUE))
#   return(l)
# }
# 
# optim(par = 400, fn = logvero, x=datos_agregados$N)
# s <- sapply(X = m:4000, FUN = logvero, x=datos_agregados$N)
# plot(s)

```

En la @fig-ajusteab0 se muestran todos los ajustes de las distribuciones
de la clase $(a,b,0)$, lo que permite comparar y ver que la binomial
negativa es la que mejor emula el comportamiento de la dsitribución
empírica de los datos, estado, sin embargo, lejos de ser adecuado.

```{r Familia (a,b,0), echo=FALSE}
#| fig-cap: "Ajustes con distribuciones de la clase (a,b,0)"
#| label: fig-ajusteab0
#| echo: false
#| 
cdfcomp(cex=0.8, list(fit_Poisson, fit_Geom, fit_Nbinom, fit_ZTBinom), main="", xlab="Datos de frecuencia", ylab = "Función de distribución", legend=c("Poisson","Geométrica","Binomial \nnegativa", "Binomial"))
```

A su vez, en la @fig-ajusteab1trunc están los miembros de la clase
$(a,b,1)$ truncadas en cero, los cuáles no muestran ser mejores que sus
distribuciones originales en la clase $(a,b,0)$.

```{r Familia (a,b,1) truncadas , echo=FALSE}
#| fig-cap: "Ajustes con distribuciones de la clase (a,b,1) truncadas en cero"
#| label: fig-ajusteab1trunc
#| echo: false

cdfcomp(cex=0.8, list(fit_ZTPoisson, fit_ZTGeom, fit_ZTNbinom, fit_ZTBinom), main="", xlab="Datos de frecuencia", ylab = "Función de distribución", legend=c("Poisson","Geométrica","Binomial \nnegativa", "Binomial"))
```

A su vez, en la @fig-ajusteab1mod están los miembros de la clase
$(a,b,1)$ modificadas en cero, los cuáles tampoco son visiblemente
mejores que sus distribuciones originales en la clase $(a,b,0)$.

```{r Familia (a,b,1) modificadas , echo=FALSE}
#| fig-cap: "Ajustes con distribuciones de la clase (a,b,1) modificadas en cero"
#| label: fig-ajusteab1mod
#| echo: false

cdfcomp(cex=0.8, list(fit_ZMPoisson, fit_ZMGeom, fit_ZMNbinom, fit_ZMBinom), main="", xlab="Datos de frecuencia", ylab = "Función de distribución", legend=c("Poisson","Geométrica","Binomial \nnegativa", "Binomial"))
```

```{r Ajuste Poisson-Gaussiana inversa, echo=FALSE, results=FALSE}
# fit_InvGauss <- fitdist(data = datos_agregados$N, distr = "poisinvgauss", method = "mle",  start = list(mean = 50, shape = 10))
# gofstat(fit_InvGauss, discrete = TRUE)
# cdfcomp(cex=0.8, fit_InvGauss)
```

```{r Ajuste Polya-Aeppli, echo=FALSE, results=FALSE}
# library(polyaAeppli)
# fit_PolyaAeppli <- fitdist(data = datos_agregados$N, distr = "PolyaAeppli", method = "mle",  start = list(lambda = 10, prob = 0.3), lower = c(0,0), upper = c(Inf,1))
# cdfcomp(cex=0.8, fit_PolyaAeppli)
# gofstat(fit_PolyaAeppli, discrete = TRUE)
```

```{r}
#| echo: false
#| tbl-cap: "Parámetros de los modelos ajustados para la frecuencia"
#| label: tbl-parametrosFrecuencia
#| tbl-pos: 'h'

arreglo_de_parametros <- function(modelo){
par <- modelo$estimate
resultados = ""
pruebas <- gofstat(modelo, discrete = TRUE)
valor_p <- pruebas$chisqpvalue

for (i in 1:length(names(par))) {

    nombre <- paste("$\\texttt{",names(par)[i], "}$")
  if(resultados==""){
  resultados <- paste(nombre,"=",round(as.numeric(par[i]),6) )
  }else{
    resultados <- paste(resultados,",", nombre ,"=",round(as.numeric(par[i]),6) )
  }
}
temp <- c(modelo$distname, resultados)
# temp <- c(modelo$distname, resultados, round(modelo$aic,6), round(modelo$bic, 6), round(valor_p, 10))

return(temp)
}

dist_frec <- list(fit_Poisson, fit_ZTPoisson, fit_ZMPoisson, fit_Nbinom, fit_ZTNbinom, fit_ZMNbinom, 
                  fit_Geom, fit_ZTGeom, fit_ZMGeom, 
                  fit_Binom, fit_ZTBinom, fit_ZMBinom)

tabla <- cbind(sapply(dist_frec, arreglo_de_parametros)) %>% t() %>% as.data.frame()


nombres_dists <- c("Poisson"," ZT-Poisson", "ZM-Poisson",
                   "Binomial negativa", "ZT-Binomial negativa", "ZM-Binomial negativa", "Geométrica", "ZT-Geométrica", "ZM-Geométrica","Binomial", "ZT-Binomial", "ZM-Binomial")

tabla[,1] <- nombres_dists
colnames(tabla) <- c("$\\textbf{Distribución}$", "$\\textbf{Parámetros en } \\texttt{R}$")

kable(tabla, format = "latex", escape = FALSE)  %>% kable_styling(latex_options = c("striped"))%>%
  kable_styling(full_width = F)%>%
  kable_classic_2() %>%
  row_spec(0,bold=TRUE)

```

```{r}
#| echo: false
#| tbl-cap: "Métricas de los modelos ajustados para la frecuencia"
#| label: tbl-metricasFrecuencia
#| tbl-pos: 'h'
arreglo_de_metricas <- function(modelo){
par <- modelo$estimate
resultados = ""
pruebas <- gofstat(modelo, discrete = TRUE)
valor_p <- pruebas$chisqpvalue

temp <- c(modelo$distname, round(modelo$aic,8), round(modelo$bic, 8), round(valor_p, 10))

return(temp)
}

tabla <- cbind(sapply(dist_frec, arreglo_de_metricas)) %>% t() %>% as.data.frame()

nombres_dists <- c("Poisson"," ZT-Poisson", "ZM-Poisson",
                   "Binomial negativa", "ZT-Binomial negativa", "ZM-Binomial negativa", "Geométrica", "ZT-Geométrica", "ZM-Geométrica","Binomial", "ZT-Binomial", "ZM-Binomial")

tabla[,1] <- nombres_dists
colnames(tabla) <- c("Distribución", "AIC", "BIC", "Valor $p$")

kable(tabla, format = "latex", escape = FALSE)  %>% kable_styling(latex_options = c("striped"))%>%
  kable_styling(full_width = F)%>%
  kable_classic_2() %>%
  row_spec(0,bold=TRUE)
```



### Ajuste de la severidad

```{r}
#| echo: false
#| warning: false

X <- datos_agregados$X/1000

fit_lnorm <- fitdist(data = X, distr = "lnorm", method = "mle")

fit_exp <- fitdist(data = X, distr = "exp", method = "mle")

fit_gamma <- fitdist(data = X, distr = "gamma", method = "mle")

fit_JSU <- fitdist(data = X, distr = 'JSU', method = "mle", 
                   start=list(mu=0.3, sigma=1, nu=1,tau=0.4))

fit_glogis <- fitdist(data = X, distr = 'glogis', method = "mle",
                      start=list(location=0.2, scale=1, shape=1))

fit_weibull <- fitdist(data = X, distr = 'weibull', method = "mle")
```

```{r}
#| echo: false  

goftest <- gofstat(list(fit_lnorm, fit_exp, fit_gamma, 
                        fit_JSU, fit_glogis, fit_weibull))

```

```{r, warning=FALSE, message=FALSE}
#| echo: false
#| fig-cap: "Densidad de las distribuciones ajustadas con MLE"
#| label: fig-denscompSeveridad

plot.legend <- c('lnorm', 'exp', 'gamma', 'JSU', 'gLogis', 'Weibull')
denscomp(list(fit_lnorm, fit_exp, fit_gamma, fit_JSU, fit_glogis, fit_weibull),
         main = "", ylab = 'Función de densidad', xlab = 'Datos de severidad',
         legendtext = plot.legend, cex=0.8)
```

La @fig-denscompSeveridad muestra que la logística generalizada, weibull y 
Johnson SU muestran la forma que acerca más al histograma. Las otras distribuciones
no se aproximan tan bien a los datos. 

```{r}
#| echo: false
#| fig-cap: "Función cumulativa de las distribuciones ajustadas con MLE"
#| label: fig-cdfcompSeveridad
cdfcomp(cex=0.8, list(fit_lnorm, fit_exp, fit_gamma, fit_JSU, fit_glogis, 
                      fit_weibull), main = "", xlab = 'Datos de severidad',
        ylab = 'Función de distribución', legendtext = plot.legend)
```

La @fig-cdfcompSeveridad se muestra la distribución cumulativa, la cual muestra 
más claramente que las distribuciones mencionadas anteriormentes se ajustan 
mejor. En la @tbl-parametrosSeveridad se muestran los parámetros ajustados para
cada modelo. Se observa que los modelos más adecuados, al menos visualmente, son 
más complejos al tener tres y cuatro parámetros

```{r}
#| echo: false
#| tbl-cap: "Parámetros de los modelos ajustados para la severidad"
#| label: tbl-parametrosSeveridad
#| tbl-pos: 'h'

arreglo_de_parametros <- function(modelo){
par <- modelo$estimate
resultados = ""

for (i in 1:length(names(par))) {

    nombre <- paste("$\\texttt{",names(par)[i], "}$")
  if(resultados==""){
  resultados <- paste(nombre,"=",round(as.numeric(par[i]),6) )
  }else{
    resultados <- paste(resultados,",", nombre ,"=",round(as.numeric(par[i]),6) )
  }
}
temp <- c(modelo$distname, resultados)
# temp <- c(modelo$distname, resultados, round(modelo$aic,6), round(modelo$bic, 6), round(valor_p, 10))

return(temp)
}


dist_sev <- list(fit_lnorm, fit_exp, fit_gamma, 
            fit_JSU, fit_glogis, fit_weibull)

tabla <- cbind(sapply(dist_sev, arreglo_de_parametros)) %>% t() %>% as.data.frame()


nombres_dists <- c("Lognormal", "Exponencial", "Gamma", "SU de Johnson", "Logística generalizada", "Weibull")

tabla[,1] <- nombres_dists
colnames(tabla) <- c("$\\textbf{Distribución}$", "$\\textbf{Parámetros en } \\texttt{R}$")

kable(tabla, format = "latex", escape = FALSE)  %>% kable_styling(latex_options = c("striped"))%>%
  kable_styling(full_width = F)%>%
  kable_classic_2() %>%
  row_spec(0,bold=TRUE)

```

```{r}
#| echo: false
#| tbl-cap: "Métricas de bondad de ajuste de la severidad"
#| label: tbl-metricasSeveridad
#| tbl-pos: 'h'

LogLik <- c(fit_lnorm$loglik, fit_exp$loglik, fit_gamma$loglik, 
            fit_JSU$loglik, fit_glogis$loglik, fit_weibull$loglik)

goft <- data.frame( dist = c('log-normal', 'exponencial', 'gamma', 
                             'Johnson SU', 'glogis', 'Weibull'), 
                    AIC = as.numeric(goftest$aic), 
                    BIC = as.numeric(goftest$bic), 
                    Loglik = LogLik, ad=as.numeric(goftest$ad), 
                    ks = as.numeric(goftest$ks))

goft %>% kbl(col.names = c('Distribución', 'AIC', 'BIC', 'LogLik', 
                'Estad. AD', 'Estad. KS'), digits = 2) %>%#| fig-cap: "Densidad de las distribuciones ajustadas con MLE"
#| label: fig-mayormontoaerolineas
                 kable_styling(latex_options = c("striped"))%>%
  kable_styling(full_width = F)%>%
  kable_classic_2() %>%
  row_spec(0,bold=TRUE)
```
\newpage

### Fichas de resultados

1.  **Nombre de Resultado**: Ajuste visual de la Severidad

    **Resumen en una oración**: En la @fig-denscompSeveridad y
    @fig-cdfcompSeveridad se observa uqe logística generalizada, Johnson
    SU y Weibull ajustan mejor a la severidad.

    **Principal característica**: Ovservando la @fig-cdfcompSeveridad,
    estas tres distribuciones se acercan más a la función de
    distribución empírica.

    **Problemas o posibles desafíos**: La logística generalizada y
    Johnson SU son distribuciones de 3 y 4 parámtetros respectivamente
    lo que puede afectar el principio de parsimonía.

    **Resumen en un párrafo**: En la @fig-denscompSeveridad se observa
    que la exponencial no presenta ningún tipo de simetría, la cual sí
    se aprecia en el histograma de la severidad. Por otro lado, la
    log-normal y la gamma no parecen coincidir en la centralidad, aparte
    de que presetan más peso en la cola derecha. La distirbuciones de
    logística generalizada, weibull y Johnson SU parecen ajustarse mejor
    al histograma y las tres presentan una forma similar. Al observar la
    @fig-cdfcompSeveridad se aprecia un comportamiento similar: la
    exponencial parece estar muy lejos mientras que las tres ya
    mencionados se acercan bastante a la distribución empírica, y la
    logística generalizada parece ser la que sigue más cercanamente.

2.  **Nombre de Resultado**: Ajuste bajo la prueba de kolmogorov-Smirnov
    para la severidad.

    **Resumen en una oración**: Se confirma que la Johnson SU, logística
    generalizada y weibull proporcionan buen ajuste para la severidad.

    **Principal característica**: Se da un no rechazo de la hipótesis
    nula para las distribuciones mencionadas con un nivel de
    significancia de 0.05.

    **Problemas o posibles desafíos**: Ninguna adicional al ya discutido

    **Resumen en un párrafo**: Para una significancia de 0.05 se tiene
    un valor crítico de $0.1962991$, por lo que se rechaza la hipótesis
    de bondad de ajuste para la gamma, la exponencial y la log-normal, y
    se no se rechaza para la Johnson SU, logística generalizada y
    weibull. Además, note que el estadístico más bajo obtenido es para
    la logística generalizada. Bajo una significancia de 0.01 se obtiene
    un valor crítico de $0.2352702$, por lo que se rechaza rotundamente
    la log-normal y la exponencial como distribuciones candidatas para
    la severidad bajo esta prueba.

3.  **Nombre de Resultado**: Ajuste bajo la prueba de Anderson-Darling
    para la severidad

    **Resumen en una oración**: Se confirma que la Johnson SU, logística
    generalizada y weibull proporcionan buen ajuste para la severidad.

    **Principal característica**: Se da un no rechazo de la hipótesis
    nula para las distribuciones mencionadas con un nivel de
    significancia de 0.05.

    **Problemas o posibles desafíos**: Ninguna adicional al ya discutido

    **Resumen en un párrafo**: Para una significancia de 0.05 se tiene
    un valor crítico de $2.492$, por lo que se rechaza la hipótesis de
    bondad de ajuste para la log-normal y exponencial, y se no se
    rechaza para la Johnson SU, logística generalizada, weibull y gamma.
    Además, note que el estadístico más bajo obtenido es para la
    logística generalizada. Bajo una significancia de 0.01 se obtiene un
    valor crítico de $3.857$, por lo que se rechaza rotundamente la
    exponencial como distribuciones candidatas para la severidad bajo
    esta prueba.

4.  **Nombre de Resultado**: AIC, BIC y versosimilitud para la severidad

    **Resumen en una oración**: La logística generalizada obtiene la
    menor verosimilitud, AIC y BIC lo que confirma que esta es la mejor
    candidata para la severidad.

    **Principal característica**: Bajo los criterios de AIC, BIC y
    verosimilitud se confirma que las mejores candidatas son la
    logística generalizada, Johnson SU y Weibull

    **Problemas o posibles desafíos**: Ninguna adicional al ya discutido

    **Resumen en un párrafo**: Entre las distribuciones ajustadas la
    logística generalizada presenta el menor valor para la
    verosimilitud, seguido por la Johnson SU y luego la Weibull. Este
    mismo comportamiento se repite con el caso del BIC. También se
    obtiene un menor valor de AIC para la logística, seguido por la
    Weibull y la Johnson SU . lo cual confirma lo que ya se había
    observado. Esto proporciona aún más evidencia de que la logística
    generalizada es la mejor candidata.

5.  **Nombre de Resultado**: Ajuste visual de la distribuciones de clase
    $(a,b,0)$ para la frecuencia

    **Resumen en una oración**: Se grafican las CDF empíricas contra las
    teóricas y ningún ajuste es bueno.

    **Principal característica**: La distribución binomial negativa
    parece el mejor ajuste.

    **Problemas o posibles desafíos**: Ninguna de las distribuciones
    básicas de frecuencia logra emular la forma de la distribución
    empírica, por lo que deben buscarse otras distribuciones discretas
    que posean una mayor flexibilidad. Además, se presentaron muchas
    dificultades de índole numérica

    **Resumen en un párrafo**: En la @fig-ajusteab0 se presentan los
    ajustes de las distribuciones de la clase $(a,b,0)$ para modelar la
    frecuencia de los reclamos. Ninguna parece emular suficientemente
    bien la forma de la distribución empírica, siendo la binomial
    negativa la que parece hacerlo mejor. Para esta distribución, se
    obtuvieron los parámetros $n=8$ y $p =265.49$ según la
    parametrización de $\texttt{R}$. Los resultado para las demás
    distribuciones, se resumen en la @tbl-parametrosFrecuencia.

6.  **Nombre de Resultado**: Ajuste visual de la distribuciones de clase
    $(a,b,1)$ para la frecuencia

    **Resumen en una oración**: Se grafican las CDF empíricas contra las
    teóricas y ningún ajuste es bueno.

    **Principal característica**: La distribución binomial negativa
    parece el mejor ajuste, tanto en el caso truncado como en el
    modificado.

    **Problemas o posibles desafíos**: Ninguna de las distribuciones
    básicas de la familia $(a,b,1)$ logra emular la forma de la
    distribución empírica, de forma que debe explorarse alguna
    alternativa que permita una mayor flexibilidad.

    **Resumen en un párrafo**: En las figuras [-@fig-ajusteab1trunc] y
    [-@fig-ajusteab1mod] se presentan los ajustes de las distribuciones
    de la clase $(a,b,1)$ para modelar la frecuencia de los reclamos.
    Ninguna parece emular suficientemente bien la forma de la
    distribución empírica, siendo la binomial negativa la que parece
    hacerlo mejor en ambos casos. Además, de las figuras
    [-@fig-ajustePoisson], [-@fig-ajustebinneg], [-@fig-ajustegeom],
    [-@fig-ajustebinom] se ve aprecia que las distribuciones de la clase
    $(a,b,1)$ son prácticamente indiscernibles respecto de las
    distribuciones correspondientes de la clase $(a,b,0)$. Además, en la
    @tbl-parametrosFrecuencia se ve que no hay mucha diferencia en los
    parámetros y en el caso de las distribuciones modificadas, la
    probabilidad en cero estimada por máxima verosimilitud se redondea
    precisamente a cero.

7.  **Nombre de Resultado**: Prueba de bondad de ajuste de las
    distribuciones de frecuencia

    **Resumen en una oración**: Se conduce una prueba Chi-Cuadrado de
    bondad de ajuste sobre todas las doce distribuciones ajustadas y
    ninguna presenta resultados adecuados.

    **Principal característica**: Se obtienen valores $p$ muy bajos, con
    lo que se rechaza la hipótesis de bondad de ajuste bajo los niveles
    de significancia usuales del $10\%$, $5\%$ y $1\%$.

    **Problemas o posibles desafíos**: La eficacia del modelo agraegado
    va a estar fuertemente comprometido si el ajuste de de la frecuencia
    es inadecaudo. Se valora probar distribuciones, como la
    Poisson-Gaussiana inversa, o la Poisson-Geométrica en procura de una
    mayor flexibilidad.

    **Resumen en un párrafo**: En la @tbl-metricasFrecuencia se presenta
    el valor $p$ resultante de la prueba Chi-Cuadrado de bondad de
    ajuste. Se obtuvieron valores $p$ muy bajos, con lo que se rechaza
    la hipótesis de bondad de ajuste bajo los niveles de significancia
    usuales del $10\%$, $5\%$ y $1\%$, de modo que hay evidencia
    suficiente para rechazar la hipótesis de que la distribución de la
    frecuencia proviene de cualquiera de las propuestas. Sin embargo,
    para continuar con las instrucciones de la bitácora 3 y en ausencia
    de un modelo alternativo mejor, se toman las distribuciones con
    mayores valores $p$, que son las binomiales negativas.

8.  **Nombre de Resultado**: Medidas AIC y BIC para la frecuencia

    **Resumen en una oración**: Los modelos binomial negativos tienen
    los valores más bajos de AIC y BIC, de entre los cuáles el mejor
    bajo estas medidas es el binomial negativo truncado en cero.

    **Principal característica**: El modelo de menor AIC y BIC es el
    binomial negativo truncado en cero, pero por una difencia ínfima
    respecto al binomial negativo.

    **Problemas o posibles desafíos**: No hay mucha diferencia entre las
    medidas para decantarse por el binomial negativo o el binomial
    negativo modificado en cero, al punto de que hay que recurrir a la
    sexta cifra decimal para decidir.

    **Resumen en un párrafo**: En la @tbl-metricasFrecuencia se
    presentan las medidas de AIC y BIC para cada modelo. Se ve que en
    general, los mejores modelos son los binomiales negativos, seguidos
    de los geométricos (que son casos especiales de los anteriores),
    Poisson y, por último, los binomiales. El modelo de menor AIC y BIC
    es el binomial negativo truncado en cero. Sin embargo, se observa
    que no hay mucha diferencia entre las medidas para decantarse por el
    binomial negativo o el binomial negativo modificado en cero, al
    punto de que hay que recurrir a la sexta cifra decimal para decidir.

    | 

### Tablas

+----------------------------------+----------------------------------+
| Primarios                        | Secundario                       |
+==================================+==================================+
| -   Teoría A: Estimación         | -   Teoría D: Uso de             |
|     paramétrica por máxima       |     distribuciones compuestas    |
|     verosimilitud                |     para el ajuste de la         |
|                                  |     frecuencia                   |
| -   Teoría B: Selección de       |                                  |
|     modelos distribucionales con | -   Hipótesis B: Distribuciones  |
|     pruebas de bondad de ajuste  |     compuestas podrían dar un    |
|                                  |     mejor ajuste de la           |
| -   Teoría C: Selección de       |     frecuencia al ser más        |
|     modelos con el criterio de   |     flexibles (se valoran por    |
|     información de Akaike (AIC)  |     ejmplo las distribuciones    |
|     y el criterio de información |     compuestas Poisson-Poisson o |
|     bayesiano (BIC)              |     Neyman tipo A;               |
|                                  |     Poisson-Geométrica o         |
| -   Resultado A: Ninguna de las  |     Polya-Aeppli; y              |
|     distribuciones de las clases |     Poisson-Gaussiana inversa)   |
|     (a,b,0) o (a,b,1) son        |                                  |
|     adecuadas para modelarla     | -   Resultado B: De las          |
|     frecuencia de los reclamos.  |     distribuciones de la clase   |
|                                  |     (a,b,0) y (a,b,1), la        |
| -   Hipótesis A: La distribución |     binomial negativa es la que  |
|     logística generalizada es la |     proporciona el mejor ajuste  |
|     más adecuada para modelar la |     a los datos de frecuencia.   |
|     severidad de los reclamos.   |                                  |
+----------------------------------+----------------------------------+

: Elementos de reporte

+--------------+------------------------------------------------------+
| Sección      | Temas a tratar                                       |
+:============:+:====================================================:+
| Introducción | 1.  Introducción al modelado de pérdidas.(primario)  |
|              | 2.  Contextualización de la problemática surgida por |
|              |     los daños a la propiedad y a las personas en     |
|              |     aeropuertos de Estados Unidos.(primario)         |
|              | 3.  Teoría de estimación paramétrica,pruebas de      |
|              |     bondad de ajuste y pérdidas agregadas.           |
|              |     (primario)                                       |
|              | 4.  Teoría de distribuciones compuestas para el      |
|              |     ajuste de frecuencia.(secundario)                |
|              | 5.  Resultados de estudios afines. (secundario)      |
+--------------+------------------------------------------------------+
| Metodología  | 1.  Introducción de la base de datos y análisis      |
|              |     descriptivo. (primario)                          |
|              |                                                      |
|              | 2.  Método A: Estimación paramétrica vía máxima      |
|              |     verosimilitud. (primario)                        |
|              |                                                      |
|              | 3.  Método B: Uso de distribuciones compuestas para  |
|              |     ajustar la frecuencia de reclamos.(secundarios)  |
|              |                                                      |
|              | 4.  Selección de modelos mediante pruebas de bondad  |
|              |     de ajuste: Chi-Cuadrado, Kolmogorov-Smirnov y    |
|              |     Anderson-Darling para modelos obtenidos por      |
|              |     método A. (primario)                             |
|              |                                                      |
|              | 5.  Selección de modelos mediante AIC y BIC.         |
|              |     (primario).                                      |
|              |                                                      |
|              | 6.  Método de recursión (Fórmula de Panjer) para los |
|              |     modelos seleccionados según método B.            |
|              |     (secundario)                                     |
+--------------+------------------------------------------------------+
| Resultados   | 1.  Resultado A: Ninguna de las distribuciones de    |
|              |     las clases (a,b,0) o (a,b,1) son adecuadas para  |
|              |     modelar la frecuencia de reclamos.(primario)     |
|              |                                                      |
|              | 2.  Resultado B: Entre las distribuciones de clases  |
|              |     (a,b,0) y (a,b,1) la binomial negativa es la que |
|              |     proporciona el mejor ajuste a los datos de       |
|              |     frecuencia.(secundario)                          |
|              |                                                      |
|              | 3.  Resultado C: Entre las distribuciones de         |
|              |     severidad utilizadas para el ajuste de severidad |
|              |     la logística generalizadas es la más adecuada    |
|              |     para modelar la severidad de reclamos.           |
|              |     (primario)                                       |
+--------------+------------------------------------------------------+
|              |                                                      |
+--------------+------------------------------------------------------+

: Distribución de contenidos por sección.

## Parte de escritura

En @flores se establece el procedimiento base para conseguir la
distribución agregada al igual que algunos hallazgos y metodologías que
son de alta utilidad. Primero la agregación de los datos se hace
mensualmente con suma para la severidad y por frecuencia para los
reclamos. El autor nota que hay un tendencia negativa de la frecuencia y
severidad con respecto al tiempo por lo que procede a eliminarla. Luego,
el autor determina la mejor distribución para cada variable utilizando
estimación de máxima verosimilitud (MLE).

Se encuentra que la binomial negativa se ajusta mejor a las frecuencias.
No obstante, es importante señalar que este autor obtiene muy malos
ajustes para las frecuencias de reclamos, ya que al hacer los ajustes
respectivos obtiene valores $p$ de 0. Por lo que decide tomar la
binomial negativa, debido a que es la que posee menor valor en el
estadístico Chi-Cuadrado. Es por esta razón que el autor propone para el
modelado de la frecuencia mixturas discretas, dado el mal ajuste
obtenido.

En la @fig-ajusteab0 se presentan los ajustes de las distribuciones de
la clase $(a,b,0)$ para modelar la frecuencia de los reclamos de nuestro
estudio. Ninguna parece emular suficientemente bien la forma de la
distribución empírica sucediendo algo similar a lo observado en el
estudio de @flores, siendo la binomial negativa la que parece hacerlo
mejor. En las figuras [-@fig-ajusteab1trunc] y [-@fig-ajusteab1mod] se
presentan los ajustes de las distribuciones de la clase $(a,b,1)$ para
modelar la frecuencia de los reclamos. Ninguna parece emular
suficientemente bien la forma de la distribución empírica, siendo la
binomial negativa la que parece hacerlo mejor en ambos casos. Además, de
las figuras [-@fig-ajustePoisson], [-@fig-ajustebinneg],
[-@fig-ajustegeom], [-@fig-ajustebinom] se aprecia que las
distribuciones de la clase $(a,b,1)$ son prácticamente indiscernibles
respecto de las distribuciones correspondientes de la clase $(a,b,0)$.
Aunado a esto, se ve en la @tbl-parametrosFrecuencia que no hay mucha
diferencia en los parámetros y en el caso de las distribuciones
modificadas, la probabilidad en cero estimada por máxima verosimilitud
se redondea precisamente a cero.

@cyprian, en su estudio propone el modelado de la severidad mediante
distribuciones continuas (Exponencial, Gamma, Pareto, Lognormal y
Weibull) y discretas (Binomial, Geométrica, Binomial Negativa, Poisson)
para el caso de la frecuencia, donde los parámetros se estiman vía
máxima verosimilitud y los ajustes se miden con pruebas Chi-Cuadrado
(para la frecuencia) , Kolmogorov-Smirnov y Anderson-Darling (para la
severidad).

Una vez obtenidos los parámetros y realizadas las pruebas de ajuste, se
seleccionan los modelos de acuerdo a sus medidas del Criterio de
Información de Akaike (AIC) y el Criterio de Información Bayesiano
(BIC).

En nuestro estudio, se decide seguir esta línea de razonamiento y la
implementación de las pruebas de modelos realizadas por @cyprian.

Respecto a la severidad, de la @fig-denscompSeveridad se observa que la
distribución exponencial no presenta ningún tipo de simetría, la cual sí
se aprecia en el histograma de la severidad. Por otro lado, la
log-normal y la gamma no parecen coincidir en la centralidad, aparte de
que presentan más peso en la cola derecha. La distribuciones de
logística generalizada, Weibull y Johnson SU parecen ajustarse mejor al
histograma y las tres presentan una forma similar. Al observar la
@fig-cdfcompSeveridad se aprecia un comportamiento similar: la
exponencial parece estar muy lejos mientras que las tres ya mencionados
se acercan bastante a la distribución empírica, y la logística
generalizada parece ser la que sigue más cercanamente.

En la @tbl-metricasFrecuencia se presenta el valor $p$ resultante de la
prueba Chi-Cuadrado de bondad de ajuste en el caso de la frecuencia. Se
obtuvieron valores $p$ muy bajos, con lo que se rechaza la hipótesis de
bondad de ajuste bajo los niveles de significancia usuales del $10\%$,
$5\%$ y $1\%$, de modo que hay evidencia suficiente para rechazar la
hipótesis de que la distribución de la frecuencia proviene de cualquiera
de las propuestas. Establecido esto, en ausencia de un modelo
alternativo mejor, se toman las distribuciones con mayores valores $p$,
que son las binomiales negativas. Obsérvese que este inconveniente
coincide con el documentado por @flores.

A su vez, en la @tbl-metricasFrecuencia se presentan las medidas de AIC
y BIC para cada modelo de frecuencia. Se ve que, en general, los mejores
modelos son los binomiales negativos, seguidos de los geométricos (que
son casos especiales de los anteriores), Poisson y, por último, los
binomiales. El modelo de menor AIC y BIC es el binomial negativo
truncado en cero. Sin embargo, se observa que no hay mucha diferencia
entre las medidas para decantarse por el binomial negativo o el binomial
negativo modificado en cero, al punto de que hay que recurrir a la sexta
cifra decimal para decidir por el primero.

Como se mencionó, @flores sugiere usar distribuciones compuestas para la
frecuencia, enfoque que se tratará de adoptar para conseguir un mejor
ajuste, bajo la forma específica de tres modelos: Poisson-Poisson o
Neyman tipo A; Poisson-Geométrica o Polya-Aeppli; y Poisson-Gaussiana
inversa. Además, como una idea tentativa, se encontró el uso de
versiones discretas de distribuciones continuas descritas, por ejemplo,
en @chakraborty2015generating y @vila2019theoretical, que además se han
aplicado en seguros, tal como se retrata en @lyu2022discrete.

Por otro lado, para la severidad, según lo establece @flores, la
Log-Laplace se ajusta mejor a los reclamos por daños a la propiedad y la
lognormal se ajusta mejor a los reclamos por pérdidas de los bienes, por
lo que se utilizan estas dos para modelar la severidad.

En un estudio similar, @pitt2011estimation utilizan datos de costos de
reclamos hechos a una aseguradora española por accidentes ocurridos en
el año 2000 y recopilados en 2002, que incluye tanto los ligados a
costos por daños a la propiedad como por costos médicos. Al igual que el
estudio de @flores, para estimar la densidad para cada uno de los
costos (daños a la propiedad y médicos) se utilizan métodos paramétricos
como las aproximaciones normales y log-normales. En general, de las
propuestas paramétricas, la log-normal
tuvo un mejor desempeño en el estudio de @pitt2011estimation, que es
algo que concuerda con el de @flores.

Para una significancia de $0.05$, en el presente estudio se tiene un valor crítico de
$0.1962991$ según la prueba Kolmogorov-Smirnov, por lo que se rechaza la
hipótesis de bondad de ajuste para la gamma, la exponencial y la
log-normal, y no se rechaza para la Johnson SU, logística generalizada y
Weibull. Además, note que el estadístico más bajo obtenido es para la
logística generalizada. Bajo una significancia de $0.01$ se obtiene un
valor crítico de $0.2352702$, por lo que se rechaza rotundamente la
log-normal y la exponencial como distribución candidata para la
severidad bajo esta prueba.

En cuanto a la prueba de Anderson-Darling, con una significancia de
$0.05$ se tiene un valor crítico de $2.492$, por lo que se rechaza la
hipótesis de bondad de ajuste para la log-normal y exponencial, y no se
rechaza para la Johnson SU, logística generalizada, Weibull y gamma.
Además, note que el estadístico más bajo obtenido es para la logística
generalizada. Bajo una significancia de $0.01$ se obtiene un valor
crítico de $3.857$, por lo que se rechaza rotundamente la exponencial
como distribuciones candidatas para la severidad bajo esta prueba.

Entre las distribuciones ajustadas, la logística generalizada presenta
el menor valor para la verosimilitud, seguido por la Johnson SU y luego
la Weibull. Este mismo comportamiento se repite con el caso del BIC.
También se obtiene un menor valor de AIC para la logística, seguido por
la Weibull y la Johnson SU, lo cual confirma lo que ya se había
observado. Esto proporciona aún más evidencia de que la logística
generalizada es la mejor candidata.

## Parte de reflexión 

Luego de hacer la implementación del modelo escogido queda delimitado completamente 
el alcance del proyecto: Las distribuciones candidatas escogidas, las pruebas 
de bondad de ajuste: AIC, BIC, Kolmogorov-Smirnov, Anderson-Darling y 
Chi-cuadrado. Se encuentran resultados muy alentadores para la severidad y se 
logra ajustar parcialmente la frecuencia. Con esto se logra responder 
parcialmente la pregunta de investigación. A la UVE se le agrega las conclusiones
obtenidas y se adjunta a continuación

![Actualización de de la UVE Heurística 3](Images/UVE Maik 3.png){#fig-UVE2 fig-align="center" width="600"}
